{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import HTML\n",
    "\n",
    "from Model import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "manualSeed = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f96bf716470>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_session = False\n",
    "\n",
    "# Dataset and dataloader\n",
    "dataroot = \"data/room-rater\"\n",
    "image_size = 256\n",
    "workers = 2\n",
    "batch_size = 64\n",
    "\n",
    "# Training parameters\n",
    "n_epochs = 10\n",
    "lr = 0.001\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(root=dataroot, transform=transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CUDA: True\n"
    }
   ],
   "source": [
    "print('CUDA: {}'.format(torch.cuda.is_available()))\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "run_cuda = torch.cuda.is_available() and ngpu > 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_images, fixed_labels = next(iter(dataloader))\n",
    "fixed_images = fixed_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_progress(predictions):\n",
    "    classes = np.array([str(i) for i in range(11)])\n",
    "\n",
    "    images = fixed_images.numpy()\n",
    "    labels = fixed_labels.numpy()\n",
    "    predictions = predictions.numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(len(images), 2, figsize=(4, 18))\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        pred_ind = np.argsort(predictions[i])[-3:]\n",
    "        pred_disp = predictions[i][pred_ind]\n",
    "        class_disp = classes[pred_ind]\n",
    "        true_rating = labels[i]\n",
    "\n",
    "        pred_disp = np.exp(pred_disp) / sum(np.exp(pred_disp))\n",
    "\n",
    "        # axs[i][0].set_title('True rating: {}'.format(true_rating))\n",
    "        image = (np.transpose(image, (1, 2, 0)) / 2) + 0.5\n",
    "        axs[i][0].imshow((image * 255).astype(np.uint8))\n",
    "        # axs[i][0].imshow(image[0])\n",
    "\n",
    "        bars = axs[i][1].barh(class_disp, pred_disp, color='r')\n",
    "\n",
    "        if str(true_rating) in class_disp:\n",
    "            ind = np.where(class_disp == str(true_rating))[0][0]\n",
    "            bars[ind].set_color('g')\n",
    "\n",
    "        asp = np.diff(axs[i][1].get_xlim())[0] / np.diff(axs[i][1].get_ylim())[0]\n",
    "        axs[i][1].set_aspect(asp)\n",
    "    plt.savefig('class_progress.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Classifier(\n  (conv1): Conv2d(3, 32, kernel_size=(6, 6), stride=(4, 4), padding=(2, 2))\n  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n  (conv3): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (lin1): Linear(in_features=2048, out_features=1024, bias=True)\n  (lin2): Linear(in_features=1024, out_features=256, bias=True)\n  (lin3): Linear(in_features=256, out_features=64, bias=True)\n  (lin4): Linear(in_features=64, out_features=11, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "classifier = Classifier().to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    classifier = nn.DataParallel(classifier, list(range(ngpu)))\n",
    "classifier.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_session(cur_epoch, cur_iters, cur_time, loss, progress):\n",
    "    model_state = { 'state_dict': classifier.state_dict(), 'optimizer': optimizer.state_dict() }\n",
    "    log_state = { 'iters': cur_iters, 'epoch': cur_epoch + 1, 'runtime': cur_time,\n",
    "                    'loss': loss, 'progress': progress }\n",
    "    state = { 'model_state': model_state, 'log_state': log_state }\n",
    "    torch.save(state, 'checkpoints/latest.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_session(filename='checkpoints/latest.tar'):\n",
    "    if os.path.isfile(filename):\n",
    "        print('=> Loading checkpoint from {}'.format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        return checkpoint\n",
    "    else:\n",
    "        print('=> Checkpoint {} not found'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(line):\n",
    "    with open('out.txt', 'w') as file:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_progress = []\n",
    "loss_history = []\n",
    "iters, start_epoch = 0, 0\n",
    "\n",
    "runtime = ''\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('checkpoints/latest.tar') and restore_session:\n",
    "    session = load_session('checkpoints/latest.tar')\n",
    "\n",
    "    # Load logs\n",
    "    loss_history = session['log_state']['loss']\n",
    "    class_progress = session['log_state']['progress']\n",
    "    iters, start_epoch = session['log_state']['iters'], session['log_state']['epoch']\n",
    "    runtime = session['log_state']['runtime']\n",
    "\n",
    "    # Load model\n",
    "    classifier.load_state_dict(session['model_state']['state_dict'])\n",
    "    optimizer.load_state_dict(session['model_state']['optimizer'])\n",
    "\n",
    "    dt = datetime.strptime(runtime, '%H:%M:%S')\n",
    "    runtime_delta = timedelta(hours=dt.hour, minutes=dt.minute, seconds=dt.second)\n",
    "    start_time = start_time - runtime_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, n_epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = classifier(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss.item()\n",
    "        loss_history.append(running_loss)\n",
    "\n",
    "        runtime = str(datetime.now() - start_time).split('.')[:1][0]\n",
    "\n",
    "        print_progress('Runtime: \\e[32m %s \\e[0m\\n\\n[\\e[32m%d\\e[0m/\\e[32m%d\\e[0m] [\\e[32m%d\\e[0m/\\e[32m%d\\e[0m] [\\e[32m%d\\e[0m] loss: \\e[32m%.4f\\e[0m CUDA: \\e[32m%s\\e[0m' %\n",
    "            (runtime, epoch + 1, n_epochs, i, len(dataloader), iters, running_loss, run_cuda))\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                out = classifier(fixed_images.to(device)).cpu()\n",
    "            plot_class_progress(out)\n",
    "            class_progress.append(out)\n",
    "        \n",
    "        if iters % 1000 is 0 or (epoch is n_epochs - 1 and i is len(dataloader) - 1):\n",
    "            save_session(epoch, i, runtime, loss_history, class_progress)\n",
    "    \n",
    "        iters += 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "room-rater",
   "display_name": "room-rater"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}